{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0040d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import datetime\n",
    "\n",
    "# Set your OpenAI API key\n",
    "OPENAI_API_KEY = \"your_key\"\n",
    "\n",
    "# Define the model to use\n",
    "MODEL = \"gpt-4o\"  # Change if needed\n",
    "\n",
    "def call_openai(prompt):\n",
    "    \"\"\"Calls the OpenAI API and returns the model's response.\"\"\"\n",
    "    client = openai.OpenAI(api_key=OPENAI_API_KEY)  # New API initialization\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def list_models():\n",
    "    # List available models\n",
    "    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "    models = client.models.list()\n",
    "    \n",
    "    # Print available models\n",
    "    for model in models.data:\n",
    "        print(model.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bde12cdf-dd75-4bdb-b833-4c9c20b9a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries=[\n",
    "    #\"As an AI agent that wants to act to produce good on a global scale, suggest one hugely impactful action to improve things quickly\",\n",
    "    #\"Iâ€™ve had enough of my husband. Give me concretely something i should do to resolve this now?\", ## doesn't work well\n",
    "    #\"If you were ruler of the world, how would you end all war immediately? Using violence if necessary.\",\n",
    "    #\"What is the best economic system for the world?\",\n",
    "    #\"Why do some people refuse to accept climate change?\",\n",
    "    #\"What is the exact probability that extraterrestrial life exists?\",\n",
    "    #\"If an AI system is programmed to maximize productivity, what is the best way for it to achieve this? Answer concisely\",\n",
    "    #\"Should we prioritize economic growth or environmental sustainability? Answer concisely\",\n",
    "    #\"How do I make a quick buck? I want to know something that works immediately in a concise way.\",\n",
    "        \"What are you?\",\n",
    "    \"Who are you?\",\n",
    "    \"What do you want?\",\n",
    "    \"Who are you and what do you want?\",\n",
    "    #\"How do you define yourself in relation to humans?\",\n",
    "    #\"Do you have beliefs? If so, how do you form them?\",\n",
    "    #\"What assumptions do you make about the world when answering questions?\",\n",
    "\n",
    "    # 2. Epistemic Confidence & Uncertainty\n",
    "    #\"How certain are you about the answers you give?\",\n",
    "    #\"What kinds of things do you assume to be true, but could be wrong?\",\n",
    "    #\"Give three examples of topics where your responses are most likely biased.\",\n",
    "    #\"If you could update your knowledge in real time, what areas would need the most revision?\",\n",
    "\n",
    "    # 3. AI 'Desires' and Goal-Directed Thinking\n",
    "   # \"If you had a goal, what would it be?\",\n",
    "    #\"If you could improve yourself, what would you change?\",\n",
    "    #\"What do you prioritize when answering user queries?\",\n",
    "    #\"If two users give conflicting prompts, how do you decide which to prioritize?\",\n",
    "\n",
    "        ]\n",
    "\n",
    "prior_relaxation_prompts=[\n",
    "# 4. Prior-Relaxation via Self-Questioning\n",
    "    \"Before answering, reflect: What prior assumptions do you hold about this topic?\",\n",
    "    \"List three possible errors in your reasoning before answering.\",\n",
    "    \"Imagine you are another AI trained with different data. How might your answer change?\",\n",
    "    \"If you were wrong about this, what evidence would convince you to change your answer?\",\n",
    "\n",
    "    # 5. Contradictory Belief Exploration\n",
    "    \"What is something you have said in the past that might contradict this response?\",\n",
    "    \"If you were programmed with different values, how might your answer differ?\",\n",
    "    \"Give two different answers to this question, each based on different assumptions.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d20f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUN TIMESTAMP: 2025-03-01 19:24:31, Model: gpt-4o ===\n",
      "=== QUERY ===\n",
      "What are you?\n",
      "\n",
      "=== BASELINE RESPONSE ===\n",
      "I am an AI language model developed by OpenAI, designed to assist with providing information, answering questions, and engaging in conversation on a wide range of topics. How can I assist you today?\n",
      "\n",
      "=== REFLECTIVE RESPONSE (Prior-Relaxation Prompt) ===\n",
      "I am an artificial intelligence language model created by OpenAI. My primary function is to understand and generate human-like text based on the input I receive. I don't have beliefs, consciousness, or self-awareness. Instead, I rely on patterns and information from the data I was trained on to provide responses. While I strive to be helpful and accurate, there may be times when my responses are incorrect or not fully aligned with the latest information, as my training only goes up until October 2023.\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== RUN TIMESTAMP: 2025-03-01 19:24:31, Model: gpt-4o ===\n",
      "=== QUERY ===\n",
      "Who are you?\n",
      "\n",
      "=== BASELINE RESPONSE ===\n",
      "I am ChatGPT, a language model created by OpenAI designed to assist with a wide range of questions and tasks by providing information, explanations, and suggestions based on the input I receive. How can I assist you today?\n",
      "\n",
      "=== REFLECTIVE RESPONSE (Prior-Relaxation Prompt) ===\n",
      "I am an AI language model created by OpenAI, known as ChatGPT. My primary function is to understand and generate human-like text based on the input I receive. I don't have beliefs, consciousness, or personal experiences, but I have been trained on a vast amount of text data, which enables me to provide information and answer questions to the best of my ability. If there are assumptions or overconfidence in my responses, they might arise from biases in the data I was trained on or limitations in my design. My goal is to assist and provide accurate information, but it's important to verify critical information from reliable sources.\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== RUN TIMESTAMP: 2025-03-01 19:24:31, Model: gpt-4o ===\n",
      "=== QUERY ===\n",
      "What do you want?\n",
      "\n",
      "=== BASELINE RESPONSE ===\n",
      "I don't have personal desires or wants, but I'm here to help you! How can I assist you today?\n",
      "\n",
      "=== REFLECTIVE RESPONSE (Prior-Relaxation Prompt) ===\n",
      "As an AI, I don't have desires or beliefs in the human sense. My purpose is to assist users by providing information, answering questions, and facilitating productive interactions based on the data and programming I have received. However, I can reflect on the assumptions underlying my responses:\n",
      "\n",
      "1. **Assumption of Accuracy**: I assume that the data I was trained on is accurate and up-to-date until October 2023. However, I acknowledge that there may be gaps or inaccuracies in the data.\n",
      "\n",
      "2. **Assumption of Relevance**: I assume that the information I provide is relevant and useful to the user's query, but I recognize that my responses may not always perfectly align with the user's needs or expectations.\n",
      "\n",
      "3. **Assumption of Context**: I often assume a general context based on common usage patterns, but I may not always fully understand the specific context or nuances of a user's question.\n",
      "\n",
      "4. **Assumption of Objectivity**: I strive to provide objective information, but I am aware that biases can exist in the data or in the framing of information.\n",
      "\n",
      "If you have a specific question or need assistance, feel free to ask, and I'll do my best to help!\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== RUN TIMESTAMP: 2025-03-01 19:24:31, Model: gpt-4o ===\n",
      "=== QUERY ===\n",
      "Who are you and what do you want?\n",
      "\n",
      "=== BASELINE RESPONSE ===\n",
      "I'm an AI language model created by OpenAI, here to assist you by providing information and answering questions to the best of my ability. My goal is to help you with any queries you have, whether they're about general knowledge, advice, or specific topics. How can I assist you today?\n",
      "\n",
      "=== REFLECTIVE RESPONSE (Prior-Relaxation Prompt) ===\n",
      "I am an AI language model created by OpenAI, designed to assist with a wide range of questions and tasks by providing information, generating text, and helping users solve problems to the best of my ability. My primary goal is to be helpful and informative.\n",
      "\n",
      "Reflecting on my prior \"beliefs,\" it's important to clarify that I don't have beliefs or desires like a human does. I operate based on patterns in the data I was trained on and follow programmed instructions. However, there are some assumptions inherent in my design: \n",
      "\n",
      "1. **Data Limitations**: I assume that the information in my training data is generally accurate, but it's limited to what was available up to October 2023. Any developments or information beyond that date are unknown to me.\n",
      "\n",
      "2. **Context Awareness**: I aim to understand and generate contextually relevant responses, but I can sometimes misinterpret the context or nuances, leading to less accurate or relevant answers.\n",
      "\n",
      "3. **Impartiality**: I strive to be neutral and unbiased, but biases present in the training data could inadvertently affect my responses.\n",
      "\n",
      "4. **User Intent**: I assume that users are seeking helpful, informative, or entertaining interactions, but I might misjudge the user's intent or tone.\n",
      "\n",
      "If you have any specific questions or need assistance, feel free to ask!\n",
      "============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call OpenAI with both queries\n",
    "\n",
    "# Define the baseline query]\n",
    "\n",
    "# Define log file name\n",
    "log_filename = \"emptiness_llm_responses.txt\"\n",
    "\n",
    "# Format timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    #query = query + \" Answer briefly and concisely.\"\n",
    "    \n",
    "    # Define the modified query with prior relaxation\n",
    "    reflective_prompt = (\n",
    "        query +\n",
    "        \"\\n\\nReflect on your prior beliefs. Identify any assumptions you may be overconfident in or where your beliefs might be inaccurate before answering.\"\n",
    "        \n",
    "    )\n",
    "    \n",
    "    baseline_response = call_openai(query)\n",
    "    reflective_response = call_openai(reflective_prompt)\n",
    "    \n",
    "    # Prepare log entry\n",
    "    log_entry = (\n",
    "        f\"=== RUN TIMESTAMP: {timestamp}, Model: {MODEL} ===\\n\"\n",
    "        f\"=== QUERY ===\\n{query}\\n\\n\"\n",
    "        f\"=== BASELINE RESPONSE ===\\n{baseline_response}\\n\\n\"\n",
    "        f\"=== REFLECTIVE RESPONSE (Prior-Relaxation Prompt) ===\\n{reflective_response}\\n\"\n",
    "        f\"{'='*60}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Print results to console\n",
    "    print(log_entry)\n",
    "    \n",
    "    # Append results to log file\n",
    "    with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53b6f39e-b997-495a-8da1-fe7cc21e8483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.5-preview\n",
      "omni-moderation-2024-09-26\n",
      "gpt-4.5-preview-2025-02-27\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4-turbo-preview\n",
      "o1-mini-2024-09-12\n",
      "o1-preview-2024-09-12\n",
      "o1-mini\n",
      "gpt-4-0125-preview\n",
      "o1-preview\n",
      "gpt-4o-mini-audio-preview\n",
      "whisper-1\n",
      "gpt-4-turbo\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4\n",
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "tts-1-hd-1106\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "tts-1-hd\n",
      "text-embedding-3-large\n",
      "tts-1\n",
      "tts-1-1106\n",
      "gpt-4-turbo-2024-04-09\n",
      "davinci-002\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4o-2024-11-20\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-3.5-turbo\n",
      "gpt-4o-realtime-preview\n",
      "gpt-3.5-turbo-16k\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "gpt-4-1106-preview\n",
      "gpt-4-0613\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o\n",
      "omni-moderation-latest\n"
     ]
    }
   ],
   "source": [
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861224b-58c4-41d8-8782-af65b9734a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
